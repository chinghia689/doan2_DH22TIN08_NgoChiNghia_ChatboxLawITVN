from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import END, StateGraph
from rag.state import GraphState
import os
import re

# CÃ¡c pattern Ä‘á»ƒ nháº­n diá»‡n cÃ¢u chÃ o há»i
GREETING_PATTERNS = [
    r'^(hi|hello|hey|xin chÃ o|chÃ o|chÃ o báº¡n|alo|xin lá»—i|cáº£m Æ¡n|thank|thanks)[\s!?.]*$',
    r'^(báº¡n lÃ  ai|báº¡n tÃªn gÃ¬|giá»›i thiá»‡u|help|trá»£ giÃºp|hÆ°á»›ng dáº«n)[\s!?.]*$',
    r'^(ok|okay|Ä‘Æ°á»£c|tá»‘t|good|nice|great)[\s!?.]*$',
]

# Response cho greeting
GREETING_RESPONSES = {
    'greeting': """Xin chÃ o! ðŸ‘‹ TÃ´i lÃ  **Trá»£ lÃ½ AI Luáº­t** - chuyÃªn tÆ° váº¥n phÃ¡p luáº­t cÃ´ng nghá»‡ thÃ´ng tin.

TÃ´i cÃ³ thá»ƒ giÃºp báº¡n vá»:
â€¢ Luáº­t CÃ´ng nghá»‡ thÃ´ng tin
â€¢ Luáº­t Khoa há»c cÃ´ng nghá»‡  
â€¢ Luáº­t TrÃ­ tuá»‡ nhÃ¢n táº¡o
â€¢ Luáº­t An toÃ n thÃ´ng tin máº¡ng

**HÃ£y Ä‘áº·t cÃ¢u há»i phÃ¡p lÃ½** Ä‘á»ƒ tÃ´i há»— trá»£ báº¡n! 

VÃ­ dá»¥: "Äiá»u 5 Luáº­t CÃ´ng nghá»‡ thÃ´ng tin quy Ä‘á»‹nh gÃ¬?" """,
    
    'identity': """TÃ´i lÃ  **Trá»£ lÃ½ AI Luáº­t** - má»™t há»‡ thá»‘ng AI Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ tÆ° váº¥n phÃ¡p luáº­t vá» cÃ´ng nghá»‡ thÃ´ng tin.

TÃ´i sá»­ dá»¥ng cÃ´ng nghá»‡ RAG (Retrieval-Augmented Generation) Ä‘á»ƒ trÃ­ch xuáº¥t thÃ´ng tin chÃ­nh xÃ¡c tá»« cÃ¡c vÄƒn báº£n phÃ¡p luáº­t.

HÃ£y Ä‘áº·t cÃ¢u há»i vá» luáº­t Ä‘á»ƒ tÃ´i há»— trá»£ báº¡n!""",

    'thanks': """KhÃ´ng cÃ³ gÃ¬! ðŸ˜Š Náº¿u báº¡n cÃ³ thÃªm cÃ¢u há»i phÃ¡p lÃ½ nÃ o, hÃ£y há»i tÃ´i nhÃ©!""",
    
    'help': """**HÆ°á»›ng dáº«n sá»­ dá»¥ng:**

1. Äáº·t cÃ¢u há»i cá»¥ thá»ƒ vá» phÃ¡p luáº­t cÃ´ng nghá»‡ thÃ´ng tin
2. TÃ´i sáº½ tÃ¬m kiáº¿m trong vÄƒn báº£n luáº­t vÃ  tráº£ lá»i vá»›i trÃ­ch dáº«n chÃ­nh xÃ¡c
3. Má»—i cÃ¢u tráº£ lá»i Ä‘á»u cÃ³ nguá»“n gá»‘c tá»« vÄƒn báº£n phÃ¡p luáº­t

**VÃ­ dá»¥ cÃ¢u há»i:**
- "Äiá»u 10 Luáº­t An toÃ n thÃ´ng tin máº¡ng lÃ  gÃ¬?"
- "TrÃ¡ch nhiá»‡m cá»§a tá»• chá»©c theo Luáº­t Khoa há»c cÃ´ng nghá»‡?"
- "HÃ nh vi bá»‹ cáº¥m trong Luáº­t CÃ´ng nghá»‡ thÃ´ng tin?"
"""
}

def classify_input(question: str) -> str:
    """PhÃ¢n loáº¡i input: greeting, identity, thanks, help, hoáº·c legal_question"""
    q = question.lower().strip()
    
    # Check greeting
    if re.match(r'^(hi|hello|hey|xin chÃ o|chÃ o|chÃ o báº¡n|alo)[\s!?.]*$', q, re.IGNORECASE):
        return 'greeting'
    
    # Check identity question
    if re.match(r'^(báº¡n lÃ  ai|báº¡n tÃªn gÃ¬|báº¡n lÃ  gÃ¬|giá»›i thiá»‡u vá» báº¡n)[\s!?.]*$', q, re.IGNORECASE):
        return 'identity'
    
    # Check thanks
    if re.match(r'^(cáº£m Æ¡n|thank|thanks|cÃ¡m Æ¡n|ok|okay|Ä‘Æ°á»£c rá»“i|tá»‘t)[\s!?.]*$', q, re.IGNORECASE):
        return 'thanks'
    
    # Check help
    if re.match(r'^(help|trá»£ giÃºp|hÆ°á»›ng dáº«n|cÃ¡ch sá»­ dá»¥ng)[\s!?.]*$', q, re.IGNORECASE):
        return 'help'
    
    # Default: legal question
    return 'legal_question'


class RAGGraph:
    def __init__(self,retriever_chain):
        self.retriever=retriever_chain
        models='llama-3.3-70b-versatile'
        # models='llama-3.1-8b-instant'
        self.llm=ChatGroq(
            model=models,
            temperature=0,
            model_kwargs={
                "presence_penalty": 0.6,  
                "frequency_penalty": 1.2
                }
            )
        self.app=self.build_graph()

    async def retriever_node(self, state:GraphState):
        question=state['question']
        document=await self.retriever.ainvoke(question)
        return ({'document':document})
    async def generation_node(self, state:GraphState):
        try:
            question=state['question']
            document=state['document']

            context_parts=[]
            for doc in document:
                full_source=doc.metadata.get('source','Tai lieu khong ten')
                file_name=os.path.basename(full_source)
                formatted_chunks = (
                    f"---\n"
                    f"[TÃ€I LIá»†U]: {file_name}\n"
                    f"[Ná»˜I DUNG]: {doc.page_content}\n"
                    f"---"
                )
                context_parts.append(formatted_chunks)

            context_text='\n\n'.join(context_parts)

            template="""Báº¡n lÃ  Trá»£ lÃ½ PhÃ¡p lÃ½ AI chuyÃªn nghiá»‡p. Tráº£ lá»i cÃ¢u há»i phÃ¡p luáº­t CHÃNH XÃC dá»±a vÃ o tÃ i liá»‡u Ä‘Æ°á»£c cung cáº¥p.

### CONTEXT
{context}

### CÃ‚U Há»ŽI
{question}

### QUY Táº®C TRÃCH DáºªN (Báº®T BUá»˜C)

1. **Äá»ŒC Ká»¸ CÃ‚U Há»ŽI:**
   - XÃ¡c Ä‘á»‹nh CHÃNH XÃC cÃ¢u há»i: há»i vá» Äiá»u máº¥y? Khoáº£n máº¥y? 
   - CHá»ˆ tráº£ lá»i ÄÃšNG ná»™i dung Ä‘Æ°á»£c há»i
   - **QUAN TRá»ŒNG:** Náº¿u há»i "Äiá»u X" mÃ  Context KHÃ”NG cÃ³ Äiá»u X â†’ tráº£ lá»i "khÃ´ng cÃ³ thÃ´ng tin"

2. **Kiá»ƒm tra sá»‘ Äiá»u/Khoáº£n:**
   - Náº¿u cÃ¢u há»i vá» Äiá»u 5 â†’ CHá»ˆ tÃ¬m vÃ  trÃ­ch dáº«n Äiá»u 5
   - TUYá»†T Äá»I KHÃ”NG trÃ­ch dáº«n Äiá»u khÃ¡c (Äiá»u 4, 6...) Ä‘á»ƒ tráº£ lá»i vá» Äiá»u 5
   - Náº¿u Context cÃ³ Äiá»u 4, 6 nhÆ°ng KHÃ”NG cÃ³ Äiá»u 5 â†’ "TÃ i liá»‡u khÃ´ng chá»©a Äiá»u 5"

3. **XÃ¡c Ä‘á»‹nh nguá»“n:** 
   - Má»—i Ä‘oáº¡n cÃ³ dÃ²ng "[TÃ€I LIá»†U]: ..."
   - Khi trÃ­ch dáº«n PHáº¢I ghi rÃµ tÃªn vÄƒn báº£n

4. **TrÃ­ch dáº«n chÃ­nh xÃ¡c:**
   - CÃ³ Ä‘áº§y Ä‘á»§ sá»‘ Ä‘iá»u â†’ "Theo Äiá»u X, [TÃªn luáº­t]: '...ná»™i dung...'"
   - CÃ³ khoáº£n â†’ "Theo khoáº£n Y, Äiá»u X, [TÃªn luáº­t]: '...'"
   - KHÃ”NG Ä‘oÃ¡n sá»‘ Äiá»u/Khoáº£n

5. **KhÃ´ng cÃ³ thÃ´ng tin:** 
   - Tráº£ lá»i: "TÃ i liá»‡u khÃ´ng chá»©a thÃ´ng tin vá» [ná»™i dung cÃ¢u há»i cá»¥ thá»ƒ]."
   - KHÃ”NG viáº¿t pháº§n "CÄƒn cá»© phÃ¡p lÃ½" náº¿u khÃ´ng cÃ³ thÃ´ng tin

6. **Chá»‘ng hallucination:**
   - TUYá»†T Äá»I chá»‰ dÃ¹ng thÃ´ng tin tá»« Context
   - KHÃ”NG suy Ä‘oÃ¡n, KHÃ”NG dÃ¹ng kiáº¿n thá»©c bÃªn ngoÃ i
   - TrÃ¡nh: "theo hiá»ƒu biáº¿t", "thÃ´ng thÆ°á»ng", "cÃ³ thá»ƒ"

### VÃ Dá»¤

**CÃ¢u há»i:** "Äiá»u 15 cá»§a Luáº­t Khoa há»c vÃ  CÃ´ng nghá»‡ quy Ä‘á»‹nh gÃ¬?"

**Tráº£ lá»i:**
Äiá»u 15 quy Ä‘á»‹nh vá» trÃ¡ch nhiá»‡m cá»§a tá»• chá»©c khoa há»c trong viá»‡c Ä‘áº£m báº£o cháº¥t lÆ°á»£ng hoáº¡t Ä‘á»™ng nghiÃªn cá»©u vÃ  tuÃ¢n thá»§ phÃ¡p luáº­t.

**CÄƒn cá»© phÃ¡p lÃ½:**
- Theo Äiá»u 15, Luáº­t Khoa há»c vÃ  CÃ´ng nghá»‡: "Tá»• chá»©c pháº£i chá»‹u trÃ¡ch nhiá»‡m vá» cháº¥t lÆ°á»£ng sáº£n pháº©m khoa há»c vÃ  tuÃ¢n thá»§ cÃ¡c quy chuáº©n..." _(Nguá»“n: LUATKHOAHOCCONGNGHE.docx)_

---

**CÃ¢u há»i:** "Äiá»u 100 cá»§a Luáº­t An toÃ n thÃ´ng tin máº¡ng lÃ  gÃ¬?"

**Tráº£ lá»i:**
TÃ i liá»‡u khÃ´ng chá»©a thÃ´ng tin vá» Äiá»u 100 cá»§a Luáº­t An toÃ n thÃ´ng tin máº¡ng.

---

### Äá»ŠNH Dáº NG TRáº¢ Lá»œI

**CÃ¢u tráº£ lá»i:**
(Ngáº¯n gá»n, Ä‘Ãºng trá»ng tÃ¢m, 2-4 cÃ¢u)

**CÄƒn cá»© phÃ¡p lÃ½:**
- [TrÃ­ch dáº«n chÃ­nh xÃ¡c vá»›i sá»‘ Ä‘iá»u] _(Nguá»“n: tÃªn file)_

---

HÃ£y tráº£ lá»i:
"""

            prompt=ChatPromptTemplate.from_template(template)

            chain= prompt | self.llm | StrOutputParser()

            answer=await chain.ainvoke({'question':question,'context':context_text})

            return ({'generation':answer})
        except Exception as e:
            msg = str(e).lower()
            print(f"[ERROR] generation_node exception: {e}")  # Log Ä‘á»ƒ debug

            if 'rate limit' in msg or '429' in msg or 'quota' in msg:
                return {
                    'generation': 'Há»‡ thá»‘ng Ä‘ang quÃ¡ táº£i. Vui lÃ²ng thá»­ láº¡i sau Ã­t phÃºt.'
                }
            else:
                return {
                    'generation': f'ÄÃ£ xáº£y ra lá»—i trong quÃ¡ trÃ¬nh xá»­ lÃ½. Chi tiáº¿t: {str(e)}'
                }
    
    async def classifier_node(self, state: GraphState):
        """Node phÃ¢n loáº¡i input: greeting hay legal question"""
        question = state['question']
        input_type = classify_input(question)
        return {'input_type': input_type}
    
    async def greeting_node(self, state: GraphState):
        """Node xá»­ lÃ½ greeting - khÃ´ng cáº§n query RAG"""
        input_type = state.get('input_type', 'greeting')
        response = GREETING_RESPONSES.get(input_type, GREETING_RESPONSES['greeting'])
        return {'generation': response}
    
    def route_by_input_type(self, state: GraphState) -> str:
        """Router: greeting/thanks/help â†’ greeting_node, legal â†’ retriever"""
        input_type = state.get('input_type', 'legal_question')
        if input_type in ['greeting', 'identity', 'thanks', 'help']:
            return 'greeting_node'
        return 'retriever'
    
    def build_graph(self):
        workflow = StateGraph(GraphState)

        # ThÃªm cÃ¡c nodes
        workflow.add_node('classifier', self.classifier_node)
        workflow.add_node('greeting_node', self.greeting_node)
        workflow.add_node('retriever', self.retriever_node)  
        workflow.add_node('generation', self.generation_node)

        # Entry point lÃ  classifier
        workflow.set_entry_point('classifier')
        
        # Conditional edge: sau classifier, route theo loáº¡i input
        workflow.add_conditional_edges(
            'classifier',
            self.route_by_input_type,
            {
                'greeting_node': 'greeting_node',
                'retriever': 'retriever'
            }
        )
        
        # greeting_node â†’ END
        workflow.add_edge('greeting_node', END)
        
        # retriever â†’ generation â†’ END
        workflow.add_edge('retriever', 'generation')
        workflow.add_edge('generation', END)     
        
        return workflow.compile()